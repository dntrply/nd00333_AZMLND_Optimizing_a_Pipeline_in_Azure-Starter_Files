{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\r\n",
        "from azureml.train.sklearn import SKLearn\r\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\r\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\r\n",
        "from azureml.train.hyperdrive.sampling import RandomParameterSampling\r\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\r\n",
        "from azureml.train.hyperdrive.parameter_expressions import uniform\r\n",
        "import os\r\n",
        "from azureml.core import Experiment\r\n",
        "import joblib"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627344489024
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from train import clean_data"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627344497357
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "# ws = Workspace.get(name=\"udacity-project\")\n",
        "\n",
        "# Get the \"default\" workspace configuration that I did not specifically create\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Create the experiment and name it exp-udacity-project\n",
        "exp = Experiment(workspace=ws, name=\"exp-udacity-project\")\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = exp.start_logging()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1627344500462
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.exceptions import ComputeTargetException\n",
        "\n",
        "# TODO: Create compute cluster\n",
        "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
        "# max_nodes should be no greater than 4.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "\n",
        "# Use https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.compute.computetarget?view=azure-ml-py as a reference\n",
        "#\n",
        "# Name the cluster GPUCluster\n",
        "cluster_name = \"CPUCluster\"\n",
        "\n",
        "# See if it already exists\n",
        "# this ofcourse helps if you are reunning the notebook from teh start and do not\n",
        "# need to recreate the compute cluster\n",
        "try:\n",
        "    compute_cluster = ComputeTarget(ws, cluster_name)\n",
        "    # No exception thrown - Found it - use it below\n",
        "except ComputeTargetException:\n",
        "    # Did not find the compute target - will need to create one\n",
        "    # Specify the compute cluster configuration first\n",
        "    # See https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target\n",
        "    # and after clicking on Dv2\n",
        "    # see https://docs.microsoft.com/en-us/azure/machine-learning/concept-compute-target\n",
        "\n",
        "    # CPU cluster instance - from the Microsoft recommended options\n",
        "    cluster_config = AmlCompute.provisioning_configuration(vm_size = 'Standard_DS3_v2',\n",
        "                                                            max_nodes=4,\n",
        "                                                            description='CPU Compute Cluster created programatically')\n",
        "\n",
        "    # Next, create the cluster\n",
        "    compute_cluster = ComputeTarget.create(ws, cluster_name, cluster_config)\n",
        "\n",
        "# We have a compute cluster - either newly created - or created earlier\n",
        "# We may wait for the create operation to complete\n",
        "compute_cluster.wait_for_completion(show_output=True)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1627344501308
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.environment import Environment\n",
        "from azureml.core import ScriptRunConfig\n",
        "# Specify parameter sampler\n",
        "# ps = ### YOUR CODE HERE ###\n",
        "\n",
        "# Prepare to use teh Azure ML HyperDrive operational workflow\n",
        "# Essentially, HyperDrive will\n",
        "# - invoke the training script multiple times, each time with differnet ML hyper parameters (--C and --max_iter in this case)\n",
        "# - the script will log the hyper parameters, the accuracy and the model (all instrumentation) for each invocation\n",
        "#\n",
        "# THe workflow is to\n",
        "# - prepare the run configuration\n",
        "# - prepare all the other parameters\n",
        "# - \"Submit\" the experiment and let the HyperDrive pipeline do it's things\n",
        "# - Determine the best run\n",
        "# - Retrieve and register the model from the best run\n",
        "# \n",
        "# A lot of rederence information may be found at \n",
        "# \"Hyperparameter tuning a model with Azure Machine Learning\" - https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters\n",
        "\n",
        "# import normal and choice as they are used below in the parameter sampling\n",
        "\n",
        "from azureml.train.hyperdrive.parameter_expressions import normal, choice\n",
        "\n",
        "# from train.py - we know that the parameters are --C and --max_iter\n",
        "# train.py uses the scikit-learn LogisticRegression model\n",
        "\n",
        "ps = RandomParameterSampling({\n",
        "    \"--C\": choice(0.001, 0.01, 0.1, 1, 10),\n",
        "    \"--max_iter\": choice(100, 200, 300, 400, 500),\n",
        "})\n",
        "# Specify a Policy\n",
        "#policy = ### YOUR CODE HERE ###\n",
        "\n",
        "# BanditPolicy is a type of EarlyTerminationPolicy\n",
        "# More info can be found at \n",
        "# https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.banditpolicy?view=azure-ml-py\n",
        "\n",
        "policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1, delay_evaluation=5)\n",
        "\n",
        "\n",
        "# Create a SKLearn estimator for use with train.py\n",
        "# est = ### YOUR CODE HERE ###\n",
        "\n",
        "\n",
        "# We need to specify/provide an environment\n",
        "# We could create our own environment with corresponding yaml file\n",
        "# We may also provide an environment 'out-of-the-box' from one of the many environments provided\n",
        "\n",
        "curated_env_name = 'AzureML-Tutorial'\n",
        "curated_env = Environment.get(workspace=ws, name=curated_env_name)\n",
        "\n",
        "# SKLearn is deprecated - instead we specity the run configuration using ScriptRunConfig\n",
        "# It is necessary to pass the directory, the python script, the compute cluster and the environment\n",
        "\n",
        "run_config = ScriptRunConfig(\n",
        "    source_directory=\".\",\n",
        "    script=\"train.py\",\n",
        "    compute_target=compute_cluster,\n",
        "    environment=curated_env,\n",
        ")\n",
        "\n",
        "\n",
        "# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
        "# hyperdrive_config = ### YOUR CODE HERE ###\n",
        "hyperdrive_config = HyperDriveConfig(\n",
        "    hyperparameter_sampling=ps,\n",
        "    policy=policy,\n",
        "    run_config=run_config,\n",
        "    primary_metric_name='Accuracy',\n",
        "    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "    max_total_runs=20,\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1627344501821
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your hyperdrive run to the experiment and show run details with the widget.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "# from azureml.core import Experiment \n",
        "\n",
        "hyperdrive_run = exp.submit(config=hyperdrive_config)\n",
        "RunDetails(hyperdrive_run).show()\n",
        "hyperdrive_run.wait_for_completion(show_output=True)\n",
        "assert(hyperdrive_run.get_status() == \"Completed\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1627345086657
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get your best run and save the model from that run.\n",
        "\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "best_hyperdrive_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "\n",
        "# Get the model hyperparameter values corresponding to the best run\n",
        "print(f'********** {best_hyperdrive_run.get_details()[\"runDefinition\"][\"arguments\"]}')\n",
        "# print(best_hyperdrive_run.get_details())\n",
        "\n",
        "# Get the accuracy corresponsding to the best run\n",
        "print(f'********** Best HyperDrive run Accuracy: {best_hyperdrive_run.get_metrics()[\"Accuracy\"]}')\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1627345088004
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and download the model\r\n",
        "print(f'The file name for the model is: {best_hyperdrive_run.get_file_names()[-1]}')\r\n",
        "\r\n",
        "# download the file in the notebook context. In this case, under Users/**user**/outputs/\r\n",
        "best_hyperdrive_run.download_file(name=best_hyperdrive_run.get_file_names()[-1], output_file_path='./outputs/model.joblib')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627345088860
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model to ensure it all looks good\r\n",
        "joblib.load('./outputs/model.joblib')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627345089258
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vrify from above that --C  and --max_iter are our model values"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627345089525
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Create TabularDataset using TabularDatasetFactory\n",
        "# Data is available at: \n",
        "# \"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\"\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "# Create the Azure ML dataset from the preferred source\n",
        "# Note that thsi source is the same as used in train.py\n",
        "\n",
        "ds = TabularDatasetFactory.from_delimited_files(\"https://automlsamplenotebookdata.blob.core.windows.net/automl-sample-notebook-data/bankmarketing_train.csv\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1627345091139
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "AUTOML_DATA_DIR = 'automl_data'\n",
        "AUTOML_DATA_FILE = 'data.csv'\n",
        "\n",
        "# Use the clean_data function to clean your data.\n",
        "# x, y = clean_data(### YOUR DATA OBJECT HERE ###)\n",
        "# clean the data - function already introcuced in train.py\n",
        "X, y = clean_data(ds)\n",
        "\n",
        "# Split the data into train/test sets\n",
        "# Note that the training data would be used for AutoML; the test data is not put to use in this project\n",
        "X_train, _, y_train, _ = train_test_split(X, y, test_size=0.2)\n",
        "# Add x and y together\n",
        "# save the new df to disk as a csv\n",
        "# Upload to a datastore\n",
        "# \n",
        "# load from datastore as an Azure TabularDataSet\n",
        "\n",
        "# Add two pandas dataframes togethere\n",
        "X_train['y'] = y_train\n",
        "\n",
        "# From here on - X_train contains both input + output\n",
        "\n",
        "# save and reload the clean data so that Azure ML can use it\n",
        "# See https://stackoverflow.com/questions/60380154/upload-dataframe-as-dataset-in-azure-machine-learning\n",
        "\n",
        "# To be able to load to datastore - the data needs to be in a folder.\n",
        "# Thus first create the directory\n",
        "\n",
        "# Create a directory if \"my_data\" not in os.listdir():\n",
        "if AUTOML_DATA_DIR not in os.listdir():\n",
        "    os.mkdir('./' + AUTOML_DATA_DIR)\n",
        "else:\n",
        "    # delete contents of directory\n",
        "    os.remove('./' + AUTOML_DATA_DIR + '/' + AUTOML_DATA_FILE)\n",
        "\n",
        "\n",
        "# now save X_train to disk\n",
        "X_train.to_csv(AUTOML_DATA_DIR + '/' + AUTOML_DATA_FILE)\n",
        "\n",
        "# upload the file to the default datastore\n",
        "datastore = ws.get_default_datastore()\n",
        "\n",
        "datastore.upload(src_dir=AUTOML_DATA_DIR, target_path=AUTOML_DATA_DIR, overwrite=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1627345093519
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Now Create the dataset that will later be used for the ML Pipeline\r\n",
        "\r\n",
        "clean_ds = TabularDatasetFactory.from_delimited_files(datastore.path(AUTOML_DATA_DIR + '/' + AUTOML_DATA_FILE))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627345094617
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "import logging\n",
        "\n",
        "# Set parameters for AutoMLConfig\n",
        "# NOTE: DO NOT CHANGE THE experiment_timeout_minutes PARAMETER OR YOUR INSTANCE WILL TIME OUT.\n",
        "# If you wish to run the experiment longer, you will need to run this notebook in your own\n",
        "# Azure tenant, which will incur personal costs.\n",
        "\n",
        "#TODO here\n",
        "# From examples here - https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train\n",
        "# this dataset discusses wehther a user may be interested in a term deosit or not\n",
        "# It thus becomes a classification problem\n",
        "# The metric used is accuracy - the same that is used by the LogisticRegression in train.py\n",
        "# \n",
        "# \n",
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\" : 30,\n",
        "    \"enable_early_stopping\" : True,\n",
        "    \"iteration_timeout_minutes\" : 5,\n",
        "    \"max_concurrent_iterations\" : 4,\n",
        "    \"max_cores_per_iteration\" : -1,\n",
        "    \"n_cross_validations\" : 5,\n",
        "    \"primary_metric\" : 'accuracy',\n",
        "    \"verbosity\" : logging.INFO,\n",
        "}\n",
        "\n",
        "# Provide the remainder of the settings/configuration\n",
        "# Note that we are not providing a validation data set - and we may need to\n",
        "# \n",
        "automl_config = AutoMLConfig(\n",
        "    compute_target = compute_cluster,\n",
        "    task='classification',\n",
        "    training_data=clean_ds,\n",
        "    label_column_name='y',\n",
        "    **automl_settings)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1627345094904
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submit your automl run\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "# From https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train again\n",
        "#\n",
        "automl_run = exp.submit(config=automl_config, show_output=True)\n",
        "automl_run.wait_for_completion(show_output=True)\n",
        "assert(automl_run.get_status() == 'Completed')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627346444687
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define print_model - from https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train\r\n",
        "\r\n",
        "from pprint import pprint\r\n",
        "\r\n",
        "def print_model(model, prefix=\"\"):\r\n",
        "    for step in model.steps:\r\n",
        "        print(prefix + step[0])\r\n",
        "        if hasattr(step[1], 'estimators') and hasattr(step[1], 'weights'):\r\n",
        "            pprint({'estimators': list(e[0] for e in step[1].estimators), 'weights': step[1].weights})\r\n",
        "            print()\r\n",
        "            for estimator in step[1].estimators:\r\n",
        "                print_model(estimator[1], estimator[0]+ ' - ')\r\n",
        "        elif hasattr(step[1], '_base_learners') and hasattr(step[1], '_meta_learner'):\r\n",
        "            print(\"\\nMeta Learner\")\r\n",
        "            pprint(step[1]._meta_learner)\r\n",
        "            print()\r\n",
        "            for estimator in step[1]._base_learners:\r\n",
        "                print_model(estimator[1], estimator[0]+ ' - ')\r\n",
        "        else:\r\n",
        "            pprint(step[1].get_params())\r\n",
        "            print()  "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627346445014
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save your best automl model.\n",
        "\n",
        "### YOUR CODE HERE ###\n",
        "automl_best_run, automl_best_model = automl_run.get_output()\n",
        "\n",
        "# print the metrics:\n",
        "automl_best_run_metrics = automl_best_run.get_metrics()\n",
        "\n",
        "print(f'********** Best AutoML accuracy: {automl_best_run_metrics.get(\"accuracy\")}')\n",
        "\n",
        "print(f'********** printing Best AutoML run:\\n{automl_best_run}\\n\\nPrinting model:')\n",
        "\n",
        "print_model(automl_best_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1627346450616
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\r\n",
        "automl_best_run.get_file_names()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627346451069
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the best AutoML model to the nbotebook context\r\n",
        "joblib.dump(automl_best_model, './outputs/automl_model.joblib')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627346451530
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save and register the model\r\n",
        "automl_best_run.register_model(model_name='automl_registered_best_model.pkl', model_path='./outputs/')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627346452086
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the computecluster\r\n",
        "compute_cluster.delete"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627346452540
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "automl_best_run.get_tags()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1627346452970
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}